{
  "name": "#GetReal",
  "tagline": "Viewing CAD models in real life without having to fabricate",
  "body": "# #GetReal\r\n\r\n##Viewing CAD models in real life without having to fabricate\r\n\r\nSoftware Design Final Project, Spring 2016. \r\n\r\n#####Authors: Kevin Zhang, Cedric Kim, Daniel Daugherty, and Kevin Guo\r\n\r\n![Imgur](http://i.imgur.com/TMI6VeY.jpg)\r\n\r\n##What is #GetReal?\r\n\r\nCreators and Developers often like to tinker and make things. For software designers, testing out a new idea is as easy as the push of a keyboard button. But for hardware and mechanical-oriented enthusiasts, experimentation is time consuming and difficult, requiring either a drawn out, repetitive fabrication process of a singular object or pain-staking effort on ensuring perfection of a first-pass construction. \r\n\r\nUsing the power of augmented reality, #GetReal levels the playing field. Now you can load up an stl file of a CAD, put on some Virtual Reality Goggles, and see what your CAD would look like in 3D space, all before you even had to touch a single piece of material. Users can have access to the same kind of quick testing that software engineers do, simply making some tweaks to the CAD, re-uploading, and seeing how the changes appear in the real world. #GetReal allows for rapid prototyping and efficient iterations, streamlining the process of development for aspiring mechanical and electrical engineers.\r\n\r\n##Getting Started\r\n\r\nUsing #GetReal requires some extra hardware in addition to software dependencies in order to run the code. For external hardware, you will need: \r\n\r\n - Google Cardboard (or some other VR headset)\r\n - High Performance Webcam\r\n - A smartphone (ios or android)\r\n - SplashTop Streamer (from app store)\r\n - A special marker that consists of four blue post-it notes arranged in a square with a black dot on one of them to preserve orientation.\r\n \r\nOnce you have all your hardware, you will also need to download Python and the following python packages:\r\n \r\n - Pip `$sudo install pip`\r\n - OpenCV `$sudo pip install opencv`\r\n - OpenGL (download from website http://pyopengl.sourceforge.net/documentation/installation.html)\r\n - Numpy `$pip install numpy`\r\n - STL `$pip install numpy-stl`\r\n\r\n \r\n\r\n##Usage\r\n \r\nAfter you have your environment configured, using #GetReal is quite easy. First, assemble your hardware, such as fixing the webcam to the Google Cardboard, setting up SplashTop, etc. Then clone the repository and load your .stl flie into the folder. Run AugmentedReality.py. The program will prompt you for an stl. Type in the name of the stl you just loaded into the folder, and put on your VR headset! From your Google Cardboard, you should see your CAD model augmented into 3D space where your tracker is. Try walking around it and viewing it from different angles, and you should see the CAD model in its entirety, as if it was right in front of you. Have fun prototyping!\r\n\r\n\r\n##How it Works\r\n\r\n #GetReal is written all in Python and utilizes a Class based code structure. The mechanisms behind #GetReal consist of three main parts: Video Feed Capturing and Preprocessing, Marker Detection, and then the actual Graphics Rendering that occurs in the Visualization Controller. \r\n\r\n - Video Feed Capture - Collecting images from the webcam and calibrating the orientation of the camera and it's viewing plane. This is where any modification to the images are done before they are actually used in the major portions of the program.\r\n \r\n - Marker Detection - Using deep, complex mathematics called Quadrant Math to determine not only the four points that lie on the post-it notes, but also the four 3D projected points that would form a cube, thus creating a space in 2D that provides location and orientation for the graphical rendering.\r\n\r\n - Visualization Controller - The Graphics Renderer that processed the incoming stl file, broke it down into its triangle components, and then generated a model of within the space that Marker Detection provides as input. This is where the augmented reality actually happens.\r\n\r\nOverall, these three stages are encapsulated in a large Augmented Reality Controller, which instantiates them and runs their loops. The result is a hierarchy of classes and their methods.\r\n\r\n##What It Can Do\r\n\r\nBelow are some pictures our project. Through these examples, it is worth noting some of the strengths and limitations of the project. #GetReal is powerful in that creators can iterate very quickly with a strong source of feedback; the program is designed to be fast and lightweight. It also has additional functions to spin the stl object around and manually scale the stl, so users can see their object in motion and in more detail if they so choose. It is also quite modular, as it can take just about any stl which can be converted to from almost any CAD development platform. Some issues arise in its user experience. As it is merely a prototype, there is little room for direct manipulation with the projected object. Our project also can't view textures, and neither can it be used to manually manipulate the object. However, we believe that a lot of those additional ideas would detract from the simplicity and intuitiveness of the program. We stuck with the version in our minds most realistic for rapid prototyping. \r\n\r\n\r\n\r\n![Imgur](http://i.imgur.com/CHaRuX7.png)\r\nEarly Experimentation with OpenGL\r\n\r\n\r\n\r\n![Imgur](http://i.imgur.com/slHKOk4.png)\r\nMarker Detection and Tracking with OpenCV\r\n\r\n\r\n\r\n![Imgur](http://i.imgur.com/l6SWta7.jpg)\r\nVirtual Reality with Google Cardboard and External Webcam\r\n\r\n##How we got here\r\n\r\nOur project began with brainstorming. The team wanted to do something really cool and significant. One teammate suggested creating a CAD model visualizer, and then the next idea that got thrown out was augmented reality. So we went with that. The team decided to split into two, one pair doing the math on mark detection while the other worked on exploring VR and getting a start in OpenGL. After a week we managed to track a post note with contour lines, and we could successfully view our camera in the stereoscopic format for Google Cardboard. After the VR portion was finished, the other team began working on 3D graphic rendering and learning OpenGL. The OpenGL team was struggling real hard to learn the concepts while the math team finished creating a hough line that could detect the edges of the marker. They then worked on finding the 8 point projection space from the 4 point detection. They then began learning about how to integrate our two set of codes and setting up the appropriate structure. After a long and hard fought battle, the OpenGL team finally figured out how to draw a cube on top of an OpenCV image frame. Once all the components were set, it was time to integrate. We spent a week figuring out how to make an stl work in OpenGL and then integrating the code. Finally, we spent the remainder of the time putting everything together and linking all the pieces, from Camera to Google Cardboard.                                                                                                                 \r\n\r\n##Acknowledgements\r\n\r\nThe team would like to thank Software Design Teachers Paul Ruvolo, Ben Hill, and Oliver Steele for their guidance and expertise. We would also like to thank the NINJAs Sophia Li, Patrick Huston, Rocco Diverdi, and Lucy Wilcox for their assistance in bugs and roadblocks along the way. Finally, a big thanks from the team to its individuals for sticking it out and accomplishing such an ambitious project in a 6 week time frame.\r\n\r\n##License\r\n\r\nMIT License\r\n\r\nCopyright (c) 2016 #GetReal\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all\r\ncopies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\nSOFTWARE.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}